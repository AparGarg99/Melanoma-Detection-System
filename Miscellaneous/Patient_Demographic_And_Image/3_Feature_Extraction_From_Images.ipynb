{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6b8578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d6b8578",
    "outputId": "a4140b47-cf1d-4f7c-a66e-8ecb61b91162"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow_addons\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import skimage.io as io\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Input,Dropout,Conv2D,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose,concatenate,MaxPooling2D,Activation,Flatten,Reshape\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from skimage.io import imread,imshow\n",
    "from skimage.measure import label, regionprops, regionprops_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lVDrg-8--psW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVDrg-8--psW",
    "outputId": "8fe89293-8fac-4ad2-f7fe-b0809a7220bf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c91ea",
   "metadata": {
    "id": "668c91ea"
   },
   "source": [
    "# Define UNET Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bb296",
   "metadata": {
    "id": "982bb296"
   },
   "outputs": [],
   "source": [
    "#define orginal image shape\n",
    "ORG_IMG_WIDTH = 1024\n",
    "ORG_IMG_HEIGHT = 768\n",
    "#define UNET input shape\n",
    "IMG_HEIGHT = 192\n",
    "IMG_WIDTH = 256\n",
    "\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    conv_final = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    outputs = Reshape((IMG_HEIGHT,IMG_WIDTH))(conv_final)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6553001",
   "metadata": {
    "id": "b6553001"
   },
   "source": [
    "# Load UNET Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60d9b9",
   "metadata": {
    "id": "6e60d9b9"
   },
   "outputs": [],
   "source": [
    "def load_Unet_model(oModelPath):\n",
    "    InputImg = Input((IMG_HEIGHT,IMG_WIDTH, 3), name='img')\n",
    "    UnetModel= get_unet(InputImg, n_filters=32, dropout=0.3, batchnorm=True)\n",
    "    UnetModel.compile(optimizer=Adam(), loss=\"binary_crossentropy\")\n",
    "    UnetModel.load_weights(oModelPath)\n",
    "    return UnetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d136f77e",
   "metadata": {
    "id": "d136f77e"
   },
   "source": [
    "# Perform image segmentation to obtain mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42e49c",
   "metadata": {
    "id": "cd42e49c"
   },
   "outputs": [],
   "source": [
    "#Using the segmentation model to obtain seg mask array from image array\n",
    "\n",
    "def pre_process(image):\n",
    "    oResize = cv2.resize(image,(IMG_WIDTH,IMG_HEIGHT))\n",
    "    return oResize\n",
    "def enhance(img):\n",
    "    sub = img.flatten()\n",
    "    count = 0\n",
    "    threshold = 0.5\n",
    "    total = 0\n",
    "    for i in range(len(sub)):\n",
    "        total = total + sub[i]\n",
    "        if sub[i] > threshold:\n",
    "            count = count + 1\n",
    "    ### Added this part to handle light coloured lesions that are not segmented with threshold 0.5 ###\n",
    "    if count == 0:\n",
    "        threshold = 1.6 * total/len(sub)\n",
    "    for i in range(len(sub)):\n",
    "        if sub[i] > threshold:\n",
    "            sub[i] = 1\n",
    "        else:\n",
    "            sub[i] = 0\n",
    "    return sub\n",
    "def post_process_mask(oMask):\n",
    "    #perform closing\n",
    "    kernel = np.ones((5, 5), 'uint8')\n",
    "    oClosedMask = cv2.dilate(oMask, kernel, iterations=2)\n",
    "    oClosedMask = ndimage.binary_fill_holes(oClosedMask, structure=np.ones((5,5)))\n",
    "    return oClosedMask\n",
    "def perform_segmentation(model,image):\n",
    "    oMask = model.predict(image.reshape(1,IMG_HEIGHT,IMG_WIDTH,3))\n",
    "    #threshold the mask to make it either 1 or 0\n",
    "    oEnhancedBinaryMask = enhance(oMask)\n",
    "    #enlarge binary mask to orginal image size\n",
    "    oEnhancedBinaryMask = oEnhancedBinaryMask.reshape(IMG_HEIGHT,IMG_WIDTH)\n",
    "    oEnhancedBinaryMask = cv2.resize(oEnhancedBinaryMask, (ORG_IMG_WIDTH,ORG_IMG_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "    return oEnhancedBinaryMask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701eb10",
   "metadata": {
    "id": "4701eb10"
   },
   "source": [
    "# Set path, names of base models and load base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b832cd8",
   "metadata": {
    "id": "5b832cd8"
   },
   "outputs": [],
   "source": [
    "#set path to model folder\n",
    "def load_all_models(model_path,model_segmentation_name,model_arbitrator_name):\n",
    "  \n",
    "    UnetModel = load_Unet_model(os.path.join(model_path,model_segmentation_name))\n",
    "    \n",
    "    model_arbitrator =load_model(os.path.join(model_path,model_arbitrator_name))\n",
    "    model_arbitrator.trainable = False\n",
    "    dense_layer_output = model_arbitrator.layers[-2].output\n",
    "    new_model_arbitrator = Model(inputs=[model_arbitrator.input], outputs=dense_layer_output)\n",
    "    new_model_arbitrator.compile()\n",
    "    \n",
    "    return UnetModel,new_model_arbitrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34004f1",
   "metadata": {
    "id": "f34004f1"
   },
   "source": [
    "# ASYMMETRY PREPROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8952b4b",
   "metadata": {
    "id": "d8952b4b"
   },
   "outputs": [],
   "source": [
    "#this function gets the binary perimeter outline, used in both asymmetry and border preprocessing\n",
    "def get_perimeter(seg, seg_border, width, height):\n",
    "#getting the image perimeter from the segmentation mask\n",
    "    \n",
    "    # getting border pixels in the left to right direction\n",
    "    for i in range(height):\n",
    "        for j in range(width - 1):\n",
    "            try:\n",
    "                if seg[i][j] == 0 and seg[i][j + 1] == 1:\n",
    "                    seg_border[i][j] = 1\n",
    "                elif seg[i][j] == 1 and seg[i][j + 1] == 0:\n",
    "                    seg_border[i][j + 1] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "                \n",
    "    # getting border pixels in the right to left direction\n",
    "    for i in range(height):\n",
    "        for j in range(width - 1):\n",
    "            try:\n",
    "                if seg[i][width - j - 1] == 0 and seg[i][width - j - 2] == 1:\n",
    "                    seg_border[i][width - j - 1] = 1\n",
    "                elif seg[i][width - j - 1] == 1 and seg[i][width - j - 2] == 0:\n",
    "                    seg_border[i][width - j - 2] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "\n",
    "    # getting border pixels in the up to down direction\n",
    "    for j in range(width):\n",
    "        for i in range(height - 1):\n",
    "            try:\n",
    "                if seg[i][j] == 0 and seg[i + 1][j] == 1:\n",
    "                    seg_border[i][j] = 1\n",
    "                elif seg[i][j] == 1 and seg[i + 1][j] == 0:\n",
    "                    seg_border[i + 1][j] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "\n",
    "    # getting border pixels in the down to up direction\n",
    "    for j in range(width):\n",
    "        for i in range(height - 1):\n",
    "            try:\n",
    "                if seg[height - i - 1][j] == 0 and seg[height - i - 2][j] == 1:\n",
    "                    seg_border[height - i - 1][j] = 1\n",
    "                elif seg[height - i - 1][j] == 1 and seg[height - i - 2][j] == 0:\n",
    "                    seg_border[height - i - 2][j] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "                \n",
    "    return seg_border\n",
    "\n",
    "#get the image perimeter pixel values as a list with arrays of length 3\n",
    "def get_px_values(img, perimeter):\n",
    "    #print(perimeter.shape)\n",
    "    #this is a list that will contain arrays of length 3\n",
    "    perimeter_px_values = []\n",
    "    \n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    #print(height,width)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if perimeter[i][j] == 1:\n",
    "                perimeter_px_values.append(img[i][j])\n",
    "    \n",
    "    return perimeter_px_values\n",
    "\n",
    "#calculate the average perimeter pixel value\n",
    "def avg_pixel_values(perimeter_px_values):\n",
    "    length = len(perimeter_px_values)\n",
    "    sum_red = 0\n",
    "    sum_green = 0\n",
    "    sum_blue = 0\n",
    "    \n",
    "    for i in perimeter_px_values:\n",
    "        sum_red = sum_red + i[0]\n",
    "        sum_green = sum_green + i[1]\n",
    "        sum_blue = sum_blue + i[2]\n",
    "    return sum_red/length, sum_green/length, sum_blue/length\n",
    "\n",
    "#step 1 of the asymmetry preprocessing: replace non-lesion pixels(outside the seg mask) with the avg perimeter colour\n",
    "def asym_step_one(img, seg, avg_red, avg_green, avg_blue):\n",
    "    step_1_img = np.empty(img.shape, dtype=np.uint8)\n",
    "    \n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if seg[i][j] == 0:\n",
    "                step_1_img[i][j][0] = avg_red\n",
    "                step_1_img[i][j][1] = avg_green\n",
    "                step_1_img[i][j][2] = avg_blue\n",
    "            else:\n",
    "                step_1_img[i][j][:] = img[i][j][:]\n",
    "          \n",
    "    return step_1_img\n",
    "\n",
    "#gets the eqn parameters of major and minor axes of segmentation mask, using tangent and orientation angle(in radian)\n",
    "def get_axes_eqns(orientation, centroid_0, centroid_1):\n",
    "    \n",
    "    gradient_mj = math.tan((math.pi/2)-orientation)\n",
    "    intercept_mj = centroid_0 - gradient_mj * centroid_1\n",
    "    \n",
    "    gradient_mn = 1/(math.tan((math.pi/2)+orientation))\n",
    "    intercept_mn = centroid_0 - gradient_mn * centroid_1\n",
    "    \n",
    "    return gradient_mj, gradient_mn, intercept_mj, intercept_mn\n",
    "\n",
    "#gets the pixel difference of the reflection over both major and minor axes\n",
    "def get_px_diff(img, gradient_mj, intercept_mj, gradient_mn, intercept_mn):\n",
    "        \n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    #create empty 3d arrays to store the difference values\n",
    "    diff_arr_mj = np.empty(img.shape, dtype=np.uint8)\n",
    "    diff_arr_mn = np.empty(img.shape, dtype=np.uint8)\n",
    "    diff_arr_mjmn = np.empty(img.shape, dtype=np.uint8)\n",
    "    \n",
    "    #looping through each pixel in the image \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            #in case the gradient of the axis is zero\n",
    "            if gradient_mj !=0 and gradient_mn !=0:\n",
    "                x_dist_from_mj_axis = int(j - ((i-intercept_mj)/gradient_mj))\n",
    "                y_dist_from_mj_axis = int(i - (gradient_mj * j + intercept_mj)) \n",
    "                x_dist_from_mn_axis = int(j - ((i-intercept_mn)/gradient_mn))\n",
    "                y_dist_from_mn_axis = int(i - (gradient_mn * j + intercept_mn))\n",
    "                reflected_y_dist_from_mj_axis = x_dist_from_mj_axis\n",
    "                reflected_x_dist_from_mj_axis = y_dist_from_mj_axis\n",
    "                reflected_y_dist_from_mn_axis = x_dist_from_mn_axis\n",
    "                reflected_x_dist_from_mn_axis = y_dist_from_mn_axis\n",
    "                reflected_x_coordinate_mj = j + reflected_x_dist_from_mj_axis\n",
    "                reflected_y_coordinate_mj = i + reflected_y_dist_from_mj_axis\n",
    "                reflected_x_coordinate_mn = j + reflected_x_dist_from_mn_axis\n",
    "                reflected_y_coordinate_mn = i + reflected_y_dist_from_mn_axis            \n",
    "                reflected_x_coordinate_mjmn = j + reflected_x_dist_from_mj_axis + reflected_x_dist_from_mn_axis\n",
    "                reflected_y_coordinate_mjmn = i + reflected_y_dist_from_mj_axis + reflected_y_dist_from_mn_axis\n",
    "            elif gradient_mj == 0:\n",
    "                reflected_x_coordinate_mj = j\n",
    "                y_dist_from_mj_axis = int(i - intercept_mj)\n",
    "                reflected_y_coordinate_mj = i - 2*y_dist_from_mj_axis\n",
    "                reflected_y_coordinate_mn = i\n",
    "                x_dist_from_mn_axis = int(j - intercept_mn)\n",
    "                reflected_x_coordinate_mn = j - 2*x_dist_from_mn_axis\n",
    "                reflected_x_coordinate_mjmn = reflected_x_coordinate_mn\n",
    "                reflected_y_coordinate_mjmn = reflected_y_coordinate_mj\n",
    "            #else if gradient_mn==0\n",
    "            else:\n",
    "                reflected_x_coordinate_mn = j\n",
    "                y_dist_from_mn_axis = int(i - intercept_mn)\n",
    "                reflected_y_coordinate_mn = i - 2*y_dist_from_mn_axis\n",
    "                reflected_y_coordinate_mj = i\n",
    "                x_dist_from_mj_axis = int(j - intercept_mj)\n",
    "                reflected_x_coordinate_mj = j - 2*x_dist_from_mj_axis\n",
    "                reflected_x_coordinate_mjmn = reflected_x_coordinate_mj\n",
    "                reflected_y_coordinate_mjmn = reflected_y_coordinate_mn\n",
    "            \n",
    "            if 0 <= reflected_x_coordinate_mj < width and 0 <= reflected_y_coordinate_mj < height:\n",
    "                diff_arr_mj[i][j][:] = img[i][j][:] - img[reflected_y_coordinate_mj][reflected_x_coordinate_mj][:]\n",
    "            else:\n",
    "                diff_arr_mj[i][j][:] = 0\n",
    "                \n",
    "            if 0 <= reflected_x_coordinate_mn < width and 0 <= reflected_y_coordinate_mn < height:\n",
    "                diff_arr_mn[i][j][:] = img[i][j][:] - img[reflected_y_coordinate_mn][reflected_x_coordinate_mn][:]\n",
    "            else:\n",
    "                diff_arr_mn[i][j][:] = 0     \n",
    "                \n",
    "            if 0 <= reflected_x_coordinate_mjmn < width and 0 <= reflected_y_coordinate_mjmn < height:\n",
    "                diff_arr_mjmn[i][j][:] = img[i][j][:] - img[reflected_y_coordinate_mjmn][reflected_x_coordinate_mjmn][:]\n",
    "            else:\n",
    "                diff_arr_mjmn[i][j][:] = 0\n",
    "                \n",
    "    return diff_arr_mj, diff_arr_mn, diff_arr_mjmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e275a",
   "metadata": {
    "id": "515e275a"
   },
   "outputs": [],
   "source": [
    "def get_asym_img(img, seg):\n",
    "\n",
    "    #get the perimeter outline of the lesion in a 2d binary array\n",
    "    height = seg.shape[0]\n",
    "    width = seg.shape[1]\n",
    "    \n",
    "    seg_border = np.empty(seg.shape, dtype=np.uint8)\n",
    "    perimeter = get_perimeter(seg, seg_border, width, height)\n",
    "\n",
    "    #perimeter_px_values is a list containing arrays of length 3\n",
    "    #use perimeter outline to get the perimeter_px_values from original image\n",
    "    perimeter_px_values = get_px_values(img, perimeter)\n",
    "    \n",
    "    if len(perimeter_px_values) > 0:\n",
    "    \n",
    "        #get the average value of perimeter pixels\n",
    "        avg_red, avg_green, avg_blue = avg_pixel_values(perimeter_px_values)\n",
    "\n",
    "        #replace the non-lesion pixels with the average RGB values of the lesion perimeter\n",
    "        step_1_img = asym_step_one(img, seg, avg_red, avg_green, avg_blue)\n",
    "    \n",
    "    else:\n",
    "        step_1_img = img\n",
    "    \n",
    "    #using skimage regionprops to get orientation, centroid_0, centroid_1, to calculate the axes eqn parameters\n",
    "    label_seg = label(seg)\n",
    "    props = regionprops(label_seg)\n",
    "    gradient_mj, gradient_mn, intercept_mj, intercept_mn = get_axes_eqns(props[0].orientation, \n",
    "                                                                         props[0].centroid[0], \n",
    "                                                                         props[0].centroid[1])\n",
    "    \n",
    "    #get the 3 set of difference values\n",
    "    diff_mj, diff_mn, diff_mjmn = get_px_diff(step_1_img, gradient_mj, intercept_mj, gradient_mn, intercept_mn)\n",
    "\n",
    "    #calculate the average for each channel in each pixel\n",
    "    asym_img = np.empty(img.shape,dtype=np.uint8)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            asym_img[i][j][:] = (diff_mj[i][j][:] + diff_mn[i][j][:] + diff_mjmn[i][j][:])/3\n",
    "    \n",
    "    return asym_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa246399",
   "metadata": {
    "id": "aa246399"
   },
   "source": [
    "# BORDER PREPROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64e236",
   "metadata": {
    "id": "5d64e236"
   },
   "outputs": [],
   "source": [
    "def get_outward_pixels(img, img_border, width, height):\n",
    "#get 5 pixels outwards, left right up down direction\n",
    "\n",
    "    out_px = 5\n",
    "\n",
    "    #Getting leftward 5 pixels\n",
    "    for i in range(height):\n",
    "        for j in range(width - 1):\n",
    "            try:\n",
    "                if img[i][j] == 0 and img[i][j + 1] == 1:\n",
    "                    img_border[i][(j - out_px):j] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "\n",
    "    #Getting rightward 5 pixels\n",
    "    for i in range(height):\n",
    "        for j in range(width - 1):\n",
    "            try:\n",
    "                if img[i][width - j - 1] == 0 and img[i][width - j - 2] == 1:\n",
    "                    img_border[i][(width-j-1) : (width-j-1+out_px)] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "\n",
    "    #Getting upward 5 pixels\n",
    "    for j in range(width):\n",
    "        for i in range(height - 1):\n",
    "            try:\n",
    "                if img[i][j] == 0 and img[i + 1][j] == 1:\n",
    "                    for p in range(1, out_px+1):\n",
    "                        img_border[i-p][j] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "                \n",
    "    #Getting downward 5 pixels\n",
    "    for j in range(width):\n",
    "        for i in range(height - 1):\n",
    "            try:\n",
    "                if img[height - i - 1][j] == 0 and img[height - i - 2][j] == 1:\n",
    "                    for p in range(out_px):\n",
    "                        img_border[height-i-1+p][j] = 1  \n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "                \n",
    "    return(img_border)\n",
    "\n",
    "def get_inward_pixels(img, img_border, width, height):\n",
    "#get 20 pixels inwards, right left down up direction\n",
    "\n",
    "    inPixels = 20\n",
    "\n",
    "    #Getting rightward 20 pixels\n",
    "    for i in range(height):\n",
    "        for j in range(width - 1):\n",
    "            try:\n",
    "                if img[i][j] == 0 and img[i][j + 1] == 1:\n",
    "                    img_border[i][j+1:j+inPixels+1] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "\n",
    "    #Getting leftward 20 pixels\n",
    "    for i in range(height):\n",
    "        for j in range(width - 1):\n",
    "            try:\n",
    "                if img[i][width - j - 1] == 0 and img[i][width - j - 2] == 1:\n",
    "                    img_border[i][(width-j-1-inPixels) : (width-j-1)] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "\n",
    "    #Getting downward 20 pixels\n",
    "    for j in range(width):\n",
    "        for i in range(height - 1):\n",
    "            try:\n",
    "                if img[i][j] == 0 and img[i + 1][j] == 1:\n",
    "                    for p in range(i+1, i+1+inPixels):\n",
    "                        img_border[p][j] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "                \n",
    "    #Getting upward 20 pixels\n",
    "    for j in range(width):\n",
    "        for i in range(height - 1):\n",
    "            try:\n",
    "                if img[height - i - 1][j] == 0 and img[height - i - 2][j] == 1:\n",
    "                    for p in range(inPixels):\n",
    "                        img_border[height-i-2-p][j] = 1\n",
    "            except:\n",
    "                #print('Pixel out of range')\n",
    "                pass\n",
    "            \n",
    "    return img_border\n",
    "\n",
    "def create_border_mask(img,seg):\n",
    "\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "\n",
    "    # img_border will store the border imformation from the mask\n",
    "    seg_border = np.empty(seg.shape, dtype=int)\n",
    "    horizontal = seg.shape[1]\n",
    "    vertical = seg.shape[0]\n",
    "    \n",
    "    seg_border = get_perimeter(seg, seg_border, width, height)\n",
    "    seg_border = get_outward_pixels(seg, seg_border, width, height)\n",
    "    seg_border = get_inward_pixels(seg, seg_border, width, height)\n",
    "    \n",
    "    return seg_border\n",
    "\n",
    "def crop_border(img, img_crop, mask):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if int(mask[i][j]) != 0:\n",
    "                #to make the RGB channels correspond properly as original is loaded in BGR\n",
    "                img_crop[i][j][:] = img[i][j][:]\n",
    "            else:\n",
    "                img_crop[i][j][:] = 0\n",
    "    return img_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1813d8",
   "metadata": {
    "id": "2d1813d8"
   },
   "outputs": [],
   "source": [
    "def get_border_img(img, seg):\n",
    "    \n",
    "    #create the border mask\n",
    "    seg_border = create_border_mask(img,seg)\n",
    "    \n",
    "    #create am empty nd array with same shape as img to store the cropped img\n",
    "    img_border = np.empty(img.shape, dtype=np.uint8)\n",
    "    \n",
    "    #apply the border cropping\n",
    "    img_border = crop_border(img, img_border, seg_border)\n",
    "\n",
    "    return img_border"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcc1b1",
   "metadata": {
    "id": "3cfcc1b1"
   },
   "source": [
    "# CENTER PREPROCESSING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c944756",
   "metadata": {
    "id": "5c944756"
   },
   "outputs": [],
   "source": [
    "#function to get the center coordinates of a single segmentation mask\n",
    "def get_center_coordinates(seg):\n",
    "    \n",
    "    label_seg = label(seg)\n",
    "    props = regionprops_table(label_seg, properties=('centroid',))\n",
    "\n",
    "    y_max = seg.shape[0]\n",
    "    x_max = seg.shape[1]\n",
    "\n",
    "    y_range = np.array([props['centroid-0'][0]-112,props['centroid-0'][0]+112])\n",
    "    x_range = np.array([props['centroid-1'][0]-112,props['centroid-1'][0]+112])\n",
    "\n",
    "    #if y_range is outside of the image, shift it back in\n",
    "    if y_range[0] < 0:\n",
    "        y_range = y_range - y_range[0]\n",
    "    if y_range[1] > y_max:\n",
    "        y_range = y_range - (y_range[1] - y_max)\n",
    "\n",
    "    #if x_range is outside of the image, shift it back in\n",
    "    if x_range[0] < 0:\n",
    "        x_range = x_range - x_range[0]\n",
    "    if x_range[1] > x_max:\n",
    "        x_range = x_range - (x_range[1] - x_max)\n",
    "\n",
    "    #join y_range and x_range into a 2D array, which will be stored in a list for all images in the folder\n",
    "    center_px_range = np.array([y_range,x_range])\n",
    "    \n",
    "    return center_px_range\n",
    "\n",
    "#function to crop the center 256x256 pixels of a single image and save it to the output folder\n",
    "def center_crop(img, center_coordinate_range):\n",
    "\n",
    "    left = int(center_coordinate_range[1][0])\n",
    "    top = int(center_coordinate_range[0][0])\n",
    "    right = int(center_coordinate_range[1][1])\n",
    "    bottom = int(center_coordinate_range[0][1])\n",
    "\n",
    "    # Crop image of above dimension (It will not change original image)\n",
    "    img_cropped = img[top:bottom, left:right]\n",
    "\n",
    "    return img_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b455d2",
   "metadata": {
    "id": "86b455d2"
   },
   "outputs": [],
   "source": [
    "def get_center_img(img, seg):\n",
    "    \n",
    "    center_coordinate_range = get_center_coordinates(seg)\n",
    "    \n",
    "    #crop the center 256x256 pixels\n",
    "    center_cropped_img = center_crop(img, center_coordinate_range)\n",
    "    \n",
    "    return center_cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b73cb0",
   "metadata": {
    "id": "90b73cb0"
   },
   "source": [
    "# IMAGE RESIZE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325733f",
   "metadata": {
    "id": "8325733f"
   },
   "outputs": [],
   "source": [
    "#Resize image\n",
    "from skimage.transform import resize\n",
    "\n",
    "#preprocessing image to a nparray\n",
    "def image_resize(img):\n",
    "    image_resized = resize(img, (224,224,3),preserve_range=True, anti_aliasing=False).astype('uint8')\n",
    "    return image_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2520e",
   "metadata": {
    "id": "c4c2520e"
   },
   "source": [
    "# Preprocessing image(s) to be fed into Asymmetry, Border, Center, Whole models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c809a",
   "metadata": {
    "id": "8b2c809a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def perform_all_preprocessing(img,UnetModel):\n",
    "    oErrorFlag = 0\n",
    "    asym_img= []\n",
    "    border_img = []\n",
    "    center_img = []\n",
    "    whole_img = []\n",
    "    #get the segmentation mask of the lesion image using the segmentation model\n",
    "    #preprocess input image \n",
    "    oResizedImage = pre_process(img)\n",
    "    oBinaryMask = perform_segmentation(UnetModel,oResizedImage)\n",
    "    # post processing the predicted mask\n",
    "    oBinaryMask = post_process_mask(oBinaryMask)\n",
    "    #converting binary mask to 1-0 array\n",
    "    seg = np.empty(oBinaryMask.shape, dtype=np.uint8)\n",
    "    for i in range(seg.shape[0]):\n",
    "        for j in range(seg.shape[1]):\n",
    "            if oBinaryMask[i][j] == True:\n",
    "                seg[i][j] = 1\n",
    "            else:\n",
    "                seg[i][j] = 0\n",
    "    \n",
    "    #if the lesion contrast is too little and segmentation did not occur (even with using modified threshold), we do not perform prediction on that image\n",
    "    if 1 not in seg:\n",
    "        oErrorFlag = 1\n",
    "        return oErrorFlag,asym_img,border_img,center_img,whole_img\n",
    "        \n",
    "    else:       \n",
    "        #perform ABC preprocessing and resize\n",
    "        asym_img = image_resize(get_asym_img(img, seg))\n",
    "        border_img = image_resize(get_border_img(img, seg))\n",
    "        center_img = image_resize(get_center_img(img, seg))\n",
    "        whole_img = image_resize(img)\n",
    "        #convert lists to arrays for feeding into corresponding model    \n",
    "        asym_img = np.array(asym_img)\n",
    "        border_img = np.array(border_img)\n",
    "        center_img = np.array(center_img)\n",
    "        whole_img = np.array(whole_img)\n",
    "        #reshape it to (1,image size)\n",
    "        asym_img = np.reshape(asym_img,(1,asym_img.shape[0],asym_img.shape[1],asym_img.shape[2]))\n",
    "        border_img = np.reshape(border_img,(1,border_img.shape[0],border_img.shape[1],border_img.shape[2]))\n",
    "        center_img = np.reshape(center_img,(1,center_img.shape[0],center_img.shape[1],center_img.shape[2]))\n",
    "        whole_img = np.reshape(whole_img,(1,whole_img.shape[0],whole_img.shape[1],whole_img.shape[2]))\n",
    "        \n",
    "        return oErrorFlag,asym_img,border_img,center_img,whole_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2d7b8",
   "metadata": {
    "id": "18e2d7b8"
   },
   "source": [
    "# Create New Arbitrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5062e1d4",
   "metadata": {
    "id": "5062e1d4"
   },
   "outputs": [],
   "source": [
    "#load full base learner and freeze the layers\n",
    "def create_Arbitrator(path):\n",
    "    model = load_model(path)\n",
    "    \n",
    "    new_model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e0502",
   "metadata": {
    "id": "0a9e0502"
   },
   "source": [
    "# Extract features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZDg11yufJjmD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDg11yufJjmD",
    "outputId": "172844c6-6724-4250-b9b8-1d9d92cc89d1"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/Melanoma Project/ISIC_selected.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elI5XpRnKQiD",
   "metadata": {
    "id": "elI5XpRnKQiD"
   },
   "outputs": [],
   "source": [
    "model_path = \"/content/drive/MyDrive/Melanoma Project/Final_model\"\n",
    "model_segmentation_name = 'unet_large_jaccard_with3Augmentations.hdf5'\n",
    "model_arbitrator_name = 'Final_Arbitrator_6lyr_binaryCross_Weight5_YesAug_0.5Dropout.hdf5'\n",
    "UnetModel,model_arbitrator = load_all_models(model_path,model_segmentation_name,model_arbitrator_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca04160",
   "metadata": {
    "id": "eca04160"
   },
   "outputs": [],
   "source": [
    "def main_fuc(i):\n",
    "  try:\n",
    "    #image path\n",
    "    oImagePath = \"/content/ISIC_selected/\"+i\n",
    "    image = io.imread(oImagePath)\n",
    "    #print(image.shape)\n",
    "    oErrorFlag,asym_img,border_img,center_img,whole_img = perform_all_preprocessing(image,UnetModel)\n",
    "    #perform final prediction\n",
    "    if oErrorFlag == 0:\n",
    "        output = model_arbitrator.predict([whole_img,asym_img, border_img, center_img,whole_img])\n",
    "    else:\n",
    "        output = [[0]]\n",
    "  except:\n",
    "    output = [[0]]\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WblpHolExEl6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WblpHolExEl6",
    "outputId": "c6b8214d-7406-4018-81c6-288233a63ee5"
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(x)):\n",
    "  print(i)\n",
    "  l1.append(x[i][:-5])\n",
    "  l2.append(main_fuc(x[i])[0])\n",
    "  if(i%10==0):\n",
    "    print('*'*100)\n",
    "    df1=pd.DataFrame(zip(l1,l2),columns=['Name','Features'])\n",
    "    df2 = df1['Features'].apply(pd.Series)\n",
    "    df3 = pd.concat([df1,df2],axis=1)\n",
    "    df3 = df3.drop('Features',axis=1)\n",
    "    df3.to_csv('/content/drive/MyDrive/Melanoma Project/DataFrames/data_{}.csv'.format(str(i)),index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 2_Feature_Extraction_From_Images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
