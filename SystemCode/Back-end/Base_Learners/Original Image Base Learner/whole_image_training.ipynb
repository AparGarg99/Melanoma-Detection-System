{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages to Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install scipy\n",
    "#!pip install tensorflow-addons\n",
    "#!pip install pydot    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Imports \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Input,Dropout,Conv2D,BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data and model paths \n",
    "oTrainDataPath = \"C:\\\\Users\\\\SWONG\\\\PRS_project\\\\Img_data_only\\\\train_resized\\\\\"\n",
    "oValDataPath = \"C:\\\\Users\\\\SWONG\\\\PRS_project\\\\Img_data_only\\\\val_resized\\\\\"\n",
    "#directory to which the trained checkpoints are saved\n",
    "oModelPath = \"C:\\\\Users\\\\SWONG\\\\PRS_project\\\\Model\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8111 images belonging to 2 classes.\n",
      "Found 902 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#create training Image Generator\n",
    "oTrainGen = ImageDataGenerator( samplewise_std_normalization=False,\n",
    "                               samplewise_center=False,\n",
    "                               rotation_range=45,zoom_range=0.5,\n",
    "                               width_shift_range=0.2,height_shift_range=0.2,\n",
    "                               brightness_range = [0.7, 1.3],\n",
    "                               shear_range=0.15,horizontal_flip=True,\n",
    "                               vertical_flip=True,fill_mode=\"nearest\",\n",
    "                              )\n",
    "#create validation Image Generator\n",
    "oValGen = ImageDataGenerator( samplewise_std_normalization=False,\n",
    "                               samplewise_center=False,\n",
    "                               rotation_range=0,zoom_range=0,\n",
    "                               width_shift_range=0.0,height_shift_range=0.0,\n",
    "                               shear_range=0.0,horizontal_flip=False,\n",
    "                               vertical_flip=False,fill_mode=\"nearest\",\n",
    "                              )\n",
    "\n",
    "\n",
    "#read training data batch by batch\n",
    "oTrainingGenerator = oTrainGen.flow_from_directory(directory=oTrainDataPath,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   batch_size=16,\n",
    "                                                   classes = ['melanoma', 'non_melanoma'],\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42\n",
    "                                                   )\n",
    "#read validation data batch by batch\n",
    "oValGenerator = oValGen.flow_from_directory(directory=oValDataPath,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   batch_size=16,\n",
    "                                                   classes = ['melanoma', 'non_melanoma'],\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_2 (TFOpLambda)          (None, 224, 224, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_4 (TFOpLambda)  (None, 224, 224, 3)  0           tf.cast_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add_2 (TFOpLambda)   (None, 224, 224, 3)  0           tf.math.truediv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_5 (TFOpLambda)  (None, 224, 224, 3)  0           tf.nn.bias_add_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 230, 230, 3)  0           tf.math.truediv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1024)         4096        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          131200      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,172,929\n",
      "Trainable params: 7,087,233\n",
      "Non-trainable params: 85,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "#specify which pretrained model should be loaded \n",
    "oFlag = \"DenseNet121\"\n",
    "input_tensor = Input(shape=(224, 224, 3),dtype = tf.uint8)\n",
    "\n",
    "if oFlag ==  \"InceptionV3\":    \n",
    "    base_model = InceptionV3(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"ResNet50V2\":\n",
    "    base_model = ResNet50V2(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"MobileNetV2\":\n",
    "    x = tf.cast(input_tensor, tf.float32)\n",
    "    x = tf.keras.applications.mobilenet.preprocess_input(x)\n",
    "    base_model = MobileNetV2(input_tensor=x,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"DenseNet121\":\n",
    "    x = tf.cast(input_tensor, tf.float32)\n",
    "    x = tf.keras.applications.densenet.preprocess_input(x)\n",
    "    base_model = DenseNet121(input_tensor=x,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"EfficientNetB0\":\n",
    "    base_model = EfficientNetB0(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"EfficientNetB3\":\n",
    "    base_model = EfficientNetB3(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#add a fully-connected layer and the output layer\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# create the model\n",
    "model = Model(inputs=input_tensor, outputs=prediction)\n",
    "\n",
    "#Add Regularizer to conv and dense layers\n",
    "alpha = 1e-4\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer,Conv2D) or isinstance(layer,Dense):\n",
    "        layer.add_loss(lambda: regularizers.l2(alpha)(layer.kernel))\n",
    "    #if hasattr(layer,'bias_regularizer') and layer.use_bias:\n",
    "    #    layer.add_loss(lambda: regularizers.l2(alpha)(layer.bias))\n",
    "        \n",
    "\n",
    "model.summary()\n",
    "\n",
    "#compile the model\n",
    "oFocalLoss = tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss = \"binary_crossentropy\",metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "checkpoint_path = os.path.join(oModelPath,oFlag + \".hdf5\")\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor ='val_loss',  \n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "#create callbacks for monitoring training\n",
    "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
    "\n",
    "csv_logger      = CSVLogger(os.path.join(oModelPath,oFlag+'.csv'))\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "#create callback for reducing learning rate\n",
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, mode = 'min',min_lr=0.000005)\n",
    "\n",
    "callbacks=[cp_callback,tb_callback,csv_logger,early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "506/506 [==============================] - 269s 508ms/step - loss: 0.9642 - accuracy: 0.6508 - val_loss: 0.4260 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42601, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 2/100\n",
      "506/506 [==============================] - 266s 526ms/step - loss: 0.8101 - accuracy: 0.7385 - val_loss: 0.3911 - val_accuracy: 0.8304\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.42601 to 0.39105, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 3/100\n",
      "506/506 [==============================] - 282s 557ms/step - loss: 0.7925 - accuracy: 0.7603 - val_loss: 0.4301 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.39105\n",
      "Epoch 4/100\n",
      "506/506 [==============================] - 273s 539ms/step - loss: 0.7591 - accuracy: 0.7792 - val_loss: 0.4207 - val_accuracy: 0.7902\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.39105\n",
      "Epoch 5/100\n",
      "506/506 [==============================] - 274s 541ms/step - loss: 0.7588 - accuracy: 0.7666 - val_loss: 0.4124 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39105\n",
      "Epoch 6/100\n",
      "506/506 [==============================] - 275s 542ms/step - loss: 0.7348 - accuracy: 0.7754 - val_loss: 0.3136 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39105 to 0.31355, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 7/100\n",
      "506/506 [==============================] - 275s 543ms/step - loss: 0.7296 - accuracy: 0.7809 - val_loss: 0.2736 - val_accuracy: 0.9040\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.31355 to 0.27355, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 8/100\n",
      "506/506 [==============================] - 270s 532ms/step - loss: 0.6976 - accuracy: 0.7912 - val_loss: 0.4593 - val_accuracy: 0.7790\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27355\n",
      "Epoch 9/100\n",
      "506/506 [==============================] - 272s 538ms/step - loss: 0.7053 - accuracy: 0.7902 - val_loss: 0.3651 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27355\n",
      "Epoch 10/100\n",
      "506/506 [==============================] - 271s 535ms/step - loss: 0.6927 - accuracy: 0.7918 - val_loss: 0.3460 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27355\n",
      "Epoch 11/100\n",
      "506/506 [==============================] - 270s 532ms/step - loss: 0.6744 - accuracy: 0.7996 - val_loss: 0.3664 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27355\n",
      "Epoch 12/100\n",
      "506/506 [==============================] - 276s 545ms/step - loss: 0.6640 - accuracy: 0.8043 - val_loss: 0.3319 - val_accuracy: 0.8795\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27355\n",
      "Epoch 13/100\n",
      "506/506 [==============================] - 274s 540ms/step - loss: 0.6546 - accuracy: 0.8153 - val_loss: 0.4781 - val_accuracy: 0.7835\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27355\n",
      "Epoch 14/100\n",
      "506/506 [==============================] - 267s 528ms/step - loss: 0.6574 - accuracy: 0.8119 - val_loss: 0.2809 - val_accuracy: 0.8817\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27355\n",
      "Epoch 15/100\n",
      "506/506 [==============================] - 267s 528ms/step - loss: 0.6138 - accuracy: 0.8209 - val_loss: 0.2464 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27355 to 0.24637, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 16/100\n",
      "506/506 [==============================] - 269s 531ms/step - loss: 0.6489 - accuracy: 0.8122 - val_loss: 0.3144 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24637\n",
      "Epoch 17/100\n",
      "506/506 [==============================] - 277s 547ms/step - loss: 0.6325 - accuracy: 0.8124 - val_loss: 0.3391 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24637\n",
      "Epoch 18/100\n",
      "506/506 [==============================] - 275s 543ms/step - loss: 0.6106 - accuracy: 0.8199 - val_loss: 0.2983 - val_accuracy: 0.8817\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24637\n",
      "Epoch 19/100\n",
      "506/506 [==============================] - 268s 529ms/step - loss: 0.6028 - accuracy: 0.8250 - val_loss: 0.2625 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24637\n",
      "Epoch 20/100\n",
      "506/506 [==============================] - 270s 534ms/step - loss: 0.5932 - accuracy: 0.8235 - val_loss: 0.4245 - val_accuracy: 0.8404\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24637\n",
      "Epoch 21/100\n",
      "506/506 [==============================] - 279s 552ms/step - loss: 0.5779 - accuracy: 0.8285 - val_loss: 0.3395 - val_accuracy: 0.8471\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24637\n",
      "Epoch 22/100\n",
      "506/506 [==============================] - 299s 591ms/step - loss: 0.5907 - accuracy: 0.8294 - val_loss: 0.5273 - val_accuracy: 0.7746\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24637\n",
      "Epoch 23/100\n",
      "506/506 [==============================] - 282s 556ms/step - loss: 0.5591 - accuracy: 0.8385 - val_loss: 0.4404 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24637\n",
      "Epoch 24/100\n",
      "506/506 [==============================] - 269s 532ms/step - loss: 0.5963 - accuracy: 0.8331 - val_loss: 0.3481 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24637\n",
      "Epoch 25/100\n",
      "506/506 [==============================] - 270s 534ms/step - loss: 0.5600 - accuracy: 0.8316 - val_loss: 0.4406 - val_accuracy: 0.8337\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.24637\n",
      "Epoch 26/100\n",
      "506/506 [==============================] - 284s 561ms/step - loss: 0.5486 - accuracy: 0.8446 - val_loss: 0.5057 - val_accuracy: 0.7757\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.24637\n",
      "Epoch 27/100\n",
      "506/506 [==============================] - 321s 634ms/step - loss: 0.5526 - accuracy: 0.8341 - val_loss: 0.3537 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.24637\n",
      "Epoch 28/100\n",
      "506/506 [==============================] - 310s 612ms/step - loss: 0.5334 - accuracy: 0.8489 - val_loss: 0.5008 - val_accuracy: 0.7768\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.24637\n",
      "Epoch 29/100\n",
      "506/506 [==============================] - 279s 550ms/step - loss: 0.5201 - accuracy: 0.8539 - val_loss: 0.3788 - val_accuracy: 0.8281\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.24637\n",
      "Epoch 30/100\n",
      "506/506 [==============================] - 262s 517ms/step - loss: 0.5372 - accuracy: 0.8420 - val_loss: 0.3246 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.24637\n",
      "Epoch 31/100\n",
      "506/506 [==============================] - 260s 513ms/step - loss: 0.5309 - accuracy: 0.8555 - val_loss: 0.4488 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.24637\n",
      "Epoch 32/100\n",
      "506/506 [==============================] - 258s 509ms/step - loss: 0.5105 - accuracy: 0.8550 - val_loss: 0.2807 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.24637\n",
      "Epoch 33/100\n",
      "506/506 [==============================] - 256s 506ms/step - loss: 0.5154 - accuracy: 0.8548 - val_loss: 0.4285 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24637\n",
      "Epoch 34/100\n",
      "506/506 [==============================] - 257s 509ms/step - loss: 0.5144 - accuracy: 0.8524 - val_loss: 0.2945 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24637\n",
      "Epoch 35/100\n",
      "506/506 [==============================] - 262s 518ms/step - loss: 0.4830 - accuracy: 0.8610 - val_loss: 0.5228 - val_accuracy: 0.7913\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24637\n",
      "Epoch 36/100\n",
      "506/506 [==============================] - 268s 530ms/step - loss: 0.4712 - accuracy: 0.8656 - val_loss: 0.3767 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24637\n",
      "Epoch 37/100\n",
      "506/506 [==============================] - 266s 525ms/step - loss: 0.4829 - accuracy: 0.8626 - val_loss: 0.3258 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.24637\n",
      "Epoch 38/100\n",
      "506/506 [==============================] - 264s 522ms/step - loss: 0.4794 - accuracy: 0.8613 - val_loss: 0.2893 - val_accuracy: 0.8795\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24637\n",
      "Epoch 39/100\n",
      "506/506 [==============================] - 261s 515ms/step - loss: 0.4785 - accuracy: 0.8607 - val_loss: 0.4677 - val_accuracy: 0.7768\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.24637\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 262s 518ms/step - loss: 0.4888 - accuracy: 0.8594 - val_loss: 0.3881 - val_accuracy: 0.8337\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.24637\n",
      "Epoch 41/100\n",
      "506/506 [==============================] - 264s 522ms/step - loss: 0.4550 - accuracy: 0.8624 - val_loss: 0.2636 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.24637\n",
      "Epoch 42/100\n",
      "506/506 [==============================] - 263s 520ms/step - loss: 0.4820 - accuracy: 0.8699 - val_loss: 0.3390 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.24637\n",
      "Epoch 43/100\n",
      "506/506 [==============================] - 265s 523ms/step - loss: 0.4533 - accuracy: 0.8718 - val_loss: 0.2529 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.24637\n",
      "Epoch 44/100\n",
      "506/506 [==============================] - 263s 520ms/step - loss: 0.4721 - accuracy: 0.8714 - val_loss: 0.3679 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.24637\n",
      "Epoch 45/100\n",
      "506/506 [==============================] - 263s 520ms/step - loss: 0.4347 - accuracy: 0.8792 - val_loss: 0.3254 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.24637\n",
      "Epoch 46/100\n",
      "506/506 [==============================] - 262s 517ms/step - loss: 0.4517 - accuracy: 0.8725 - val_loss: 0.4591 - val_accuracy: 0.7991\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.24637\n",
      "Epoch 47/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.4127 - accuracy: 0.8863 - val_loss: 0.2879 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.24637\n",
      "Epoch 48/100\n",
      "506/506 [==============================] - 252s 499ms/step - loss: 0.4278 - accuracy: 0.8786 - val_loss: 0.2434 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.24637 to 0.24343, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 49/100\n",
      "506/506 [==============================] - 246s 486ms/step - loss: 0.4161 - accuracy: 0.8865 - val_loss: 0.2619 - val_accuracy: 0.8984\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.24343\n",
      "Epoch 50/100\n",
      "506/506 [==============================] - 245s 484ms/step - loss: 0.4310 - accuracy: 0.8724 - val_loss: 0.3896 - val_accuracy: 0.8248\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.24343\n",
      "Epoch 51/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.4264 - accuracy: 0.8803 - val_loss: 0.2554 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.24343\n",
      "Epoch 52/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.3847 - accuracy: 0.8944 - val_loss: 0.3438 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.24343\n",
      "Epoch 53/100\n",
      "506/506 [==============================] - 250s 494ms/step - loss: 0.4184 - accuracy: 0.8873 - val_loss: 0.3957 - val_accuracy: 0.8259\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.24343\n",
      "Epoch 54/100\n",
      "506/506 [==============================] - 251s 495ms/step - loss: 0.3735 - accuracy: 0.9007 - val_loss: 0.3343 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.24343\n",
      "Epoch 55/100\n",
      "506/506 [==============================] - 251s 496ms/step - loss: 0.4276 - accuracy: 0.8813 - val_loss: 0.2766 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.24343\n",
      "Epoch 56/100\n",
      "506/506 [==============================] - 252s 498ms/step - loss: 0.4050 - accuracy: 0.8934 - val_loss: 0.3344 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.24343\n",
      "Epoch 57/100\n",
      "506/506 [==============================] - 252s 498ms/step - loss: 0.3881 - accuracy: 0.8901 - val_loss: 0.4549 - val_accuracy: 0.8259\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.24343\n",
      "Epoch 58/100\n",
      "506/506 [==============================] - 253s 499ms/step - loss: 0.3868 - accuracy: 0.8926 - val_loss: 0.3310 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.24343\n",
      "Epoch 59/100\n",
      "506/506 [==============================] - 253s 499ms/step - loss: 0.3925 - accuracy: 0.8925 - val_loss: 0.3022 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.24343\n",
      "Epoch 60/100\n",
      "506/506 [==============================] - 253s 499ms/step - loss: 0.3827 - accuracy: 0.8943 - val_loss: 0.2673 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.24343\n",
      "Epoch 61/100\n",
      "506/506 [==============================] - 253s 500ms/step - loss: 0.3465 - accuracy: 0.9062 - val_loss: 0.2174 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.24343 to 0.21742, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 62/100\n",
      "506/506 [==============================] - 253s 501ms/step - loss: 0.3736 - accuracy: 0.9041 - val_loss: 0.2505 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.21742\n",
      "Epoch 63/100\n",
      "506/506 [==============================] - 253s 500ms/step - loss: 0.3636 - accuracy: 0.8983 - val_loss: 0.4334 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.21742\n",
      "Epoch 64/100\n",
      "506/506 [==============================] - 253s 500ms/step - loss: 0.3660 - accuracy: 0.9054 - val_loss: 0.2873 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.21742\n",
      "Epoch 65/100\n",
      "506/506 [==============================] - 254s 501ms/step - loss: 0.3747 - accuracy: 0.9003 - val_loss: 0.3072 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.21742\n",
      "Epoch 66/100\n",
      "506/506 [==============================] - 254s 501ms/step - loss: 0.3510 - accuracy: 0.9039 - val_loss: 0.2451 - val_accuracy: 0.9018\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.21742\n",
      "Epoch 67/100\n",
      "506/506 [==============================] - 254s 502ms/step - loss: 0.3329 - accuracy: 0.9122 - val_loss: 0.3498 - val_accuracy: 0.8583\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.21742\n",
      "Epoch 68/100\n",
      "506/506 [==============================] - 254s 502ms/step - loss: 0.3596 - accuracy: 0.9004 - val_loss: 0.3095 - val_accuracy: 0.8728\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.21742\n",
      "Epoch 69/100\n",
      "506/506 [==============================] - 255s 503ms/step - loss: 0.3618 - accuracy: 0.9009 - val_loss: 0.2829 - val_accuracy: 0.8917\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.21742\n",
      "Epoch 70/100\n",
      "506/506 [==============================] - 255s 503ms/step - loss: 0.3215 - accuracy: 0.9175 - val_loss: 0.3355 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.21742\n",
      "Epoch 71/100\n",
      "506/506 [==============================] - 255s 503ms/step - loss: 0.3268 - accuracy: 0.9074 - val_loss: 0.2731 - val_accuracy: 0.9051\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.21742\n",
      "Epoch 72/100\n",
      "506/506 [==============================] - 256s 505ms/step - loss: 0.3372 - accuracy: 0.9070 - val_loss: 0.2589 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.21742\n",
      "Epoch 73/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.3472 - accuracy: 0.9064 - val_loss: 0.3741 - val_accuracy: 0.8538\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.21742\n",
      "Epoch 74/100\n",
      "506/506 [==============================] - 255s 505ms/step - loss: 0.3356 - accuracy: 0.9077 - val_loss: 0.2704 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.21742\n",
      "Epoch 75/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.3400 - accuracy: 0.9071 - val_loss: 0.2478 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.21742\n",
      "Epoch 76/100\n",
      "506/506 [==============================] - 255s 503ms/step - loss: 0.3135 - accuracy: 0.9153 - val_loss: 0.2870 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.21742\n",
      "Epoch 77/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.3260 - accuracy: 0.9140 - val_loss: 0.2821 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.21742\n",
      "Epoch 78/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.3009 - accuracy: 0.9161 - val_loss: 0.3044 - val_accuracy: 0.8761\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.21742\n",
      "Epoch 79/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.3223 - accuracy: 0.9081 - val_loss: 0.2598 - val_accuracy: 0.8895\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.21742\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 256s 505ms/step - loss: 0.3194 - accuracy: 0.9132 - val_loss: 0.2851 - val_accuracy: 0.8862\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.21742\n",
      "Epoch 81/100\n",
      "506/506 [==============================] - 256s 507ms/step - loss: 0.3190 - accuracy: 0.9117 - val_loss: 0.2582 - val_accuracy: 0.9007\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.21742\n",
      "Epoch 82/100\n",
      "506/506 [==============================] - 254s 502ms/step - loss: 0.3056 - accuracy: 0.9209 - val_loss: 0.3224 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.21742\n",
      "Epoch 83/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.2919 - accuracy: 0.9198 - val_loss: 0.2414 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.21742\n",
      "Epoch 84/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.3177 - accuracy: 0.9140 - val_loss: 0.2502 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.21742\n",
      "Epoch 85/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.2934 - accuracy: 0.9188 - val_loss: 0.2513 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.21742\n",
      "Epoch 86/100\n",
      "506/506 [==============================] - 245s 484ms/step - loss: 0.3029 - accuracy: 0.9213 - val_loss: 0.2591 - val_accuracy: 0.9074\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.21742\n",
      "Epoch 87/100\n",
      "506/506 [==============================] - 244s 481ms/step - loss: 0.2860 - accuracy: 0.9232 - val_loss: 0.3362 - val_accuracy: 0.8761\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.21742\n",
      "Epoch 88/100\n",
      "506/506 [==============================] - 243s 480ms/step - loss: 0.2798 - accuracy: 0.9270 - val_loss: 0.2449 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.21742\n",
      "Epoch 89/100\n",
      "506/506 [==============================] - 253s 500ms/step - loss: 0.2870 - accuracy: 0.9216 - val_loss: 0.3348 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.21742\n",
      "Epoch 90/100\n",
      "506/506 [==============================] - 259s 511ms/step - loss: 0.2749 - accuracy: 0.9229 - val_loss: 0.3799 - val_accuracy: 0.8795\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.21742\n",
      "Epoch 91/100\n",
      "506/506 [==============================] - 264s 521ms/step - loss: 0.3033 - accuracy: 0.9221 - val_loss: 0.3451 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.21742\n",
      "Epoch 92/100\n",
      "506/506 [==============================] - 262s 518ms/step - loss: 0.2983 - accuracy: 0.9244 - val_loss: 0.3356 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.21742\n",
      "Epoch 93/100\n",
      "506/506 [==============================] - 263s 520ms/step - loss: 0.2668 - accuracy: 0.9284 - val_loss: 0.3559 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.21742\n",
      "Epoch 94/100\n",
      "506/506 [==============================] - 261s 515ms/step - loss: 0.2499 - accuracy: 0.9358 - val_loss: 0.2505 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.21742\n",
      "Epoch 95/100\n",
      "506/506 [==============================] - 266s 526ms/step - loss: 0.2774 - accuracy: 0.9267 - val_loss: 0.2503 - val_accuracy: 0.9208\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.21742\n",
      "Epoch 96/100\n",
      "506/506 [==============================] - 274s 541ms/step - loss: 0.2998 - accuracy: 0.9207 - val_loss: 0.2460 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.21742\n",
      "Epoch 97/100\n",
      "506/506 [==============================] - 275s 544ms/step - loss: 0.2775 - accuracy: 0.9271 - val_loss: 0.3257 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.21742\n",
      "Epoch 98/100\n",
      "506/506 [==============================] - 271s 536ms/step - loss: 0.2765 - accuracy: 0.9224 - val_loss: 0.3323 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.21742\n",
      "Epoch 99/100\n",
      "506/506 [==============================] - 257s 507ms/step - loss: 0.2473 - accuracy: 0.9398 - val_loss: 0.3518 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.21742\n",
      "Epoch 100/100\n",
      "506/506 [==============================] - 256s 506ms/step - loss: 0.2635 - accuracy: 0.9330 - val_loss: 0.3170 - val_accuracy: 0.8806\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.21742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fb778a14c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=oTrainingGenerator.n//oTrainingGenerator.batch_size\n",
    "STEP_SIZE_VALID=oValGenerator.n//oValGenerator.batch_size\n",
    "\n",
    "#class weights\n",
    "class_weight = {0:6, 1:1}\n",
    "\n",
    "model.fit(x=oTrainingGenerator, \n",
    "          y=None, \n",
    "          batch_size=16, \n",
    "          epochs=100, \n",
    "          verbose=1, \n",
    "          callbacks=callbacks, \n",
    "          validation_data=oValGenerator,\n",
    "          shuffle=True,\n",
    "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "          class_weight = class_weight,\n",
    "          validation_steps=STEP_SIZE_VALID,\n",
    "          validation_batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot curves on validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= False\n",
    "plt.rcParams['ytick.left']      = True\n",
    "plt.rcParams['ytick.labelleft'] = True\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "records     = pd.read_csv(os.path.join(oModelPath,oFlag+'.csv'))\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.1,0.2,0.3,0.4,0.50])\n",
    "plt.title('Loss curve',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_accuracy'],label=\"validation\")\n",
    "plt.plot(records['accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9])\n",
    "plt.title('Accuracy curve',fontsize=12)\n",
    "ax.legend()\n",
    "#save the plot\n",
    "plotpath  = os.path.join(oModelPath,oFlag + '_plot.png')\n",
    "plt.savefig(plotpath)\n",
    "#Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Save the model plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Path to plot: D:\\PRS_project\\Model\\MobileNetV2_plot.png\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\rggop\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\rggop\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
