{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages to Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "#!pip install scipy\n",
    "#!pip install tensorflow-addons\n",
    "#!pip install pydot    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Imports \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Input,Dropout,Conv2D,BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data and model paths \n",
    "oTrainDataPath = \"C:\\\\Users\\\\SWONG\\\\PRS_project\\\\Border_data\\\\train\\\\\"\n",
    "oValDataPath = \"C:\\\\Users\\\\SWONG\\\\PRS_project\\\\Border_data\\\\val\\\\\"\n",
    "#directory to which the trained checkpoints are saved\n",
    "oModelPath = \"C:\\\\Users\\\\SWONG\\\\PRS_project\\\\Model\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8111 images belonging to 2 classes.\n",
      "Found 902 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#create training Image Generator\n",
    "oTrainGen = ImageDataGenerator( samplewise_std_normalization=False,\n",
    "                               samplewise_center=False,\n",
    "                               rotation_range=45,zoom_range=0.5,\n",
    "                               width_shift_range=0.2,height_shift_range=0.2,\n",
    "                               brightness_range = [0.7, 1.3],\n",
    "                               shear_range=0.15,horizontal_flip=True,\n",
    "                               vertical_flip=True,fill_mode=\"nearest\",\n",
    "                              )\n",
    "#create validation Image Generator\n",
    "oValGen = ImageDataGenerator( samplewise_std_normalization=False,\n",
    "                               samplewise_center=False,\n",
    "                               rotation_range=0,zoom_range=0,\n",
    "                               width_shift_range=0.0,height_shift_range=0.0,\n",
    "                               shear_range=0.0,horizontal_flip=False,\n",
    "                               vertical_flip=False,fill_mode=\"nearest\",\n",
    "                              )\n",
    "\n",
    "\n",
    "#read training data batch by batch\n",
    "oTrainingGenerator = oTrainGen.flow_from_directory(directory=oTrainDataPath,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   batch_size=16,\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42\n",
    "                                                   )\n",
    "#read validation data batch by batch\n",
    "oValGenerator = oValGen.flow_from_directory(directory=oValDataPath,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   color_mode=\"rgb\",\n",
    "                                                   batch_size=16,\n",
    "                                                   class_mode=\"binary\",\n",
    "                                                   shuffle=True,\n",
    "                                                   seed=42\n",
    "                                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 224, 224, 3)  0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.bias_add (TFOpLambda)     (None, 224, 224, 3)  0           tf.math.truediv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_1 (TFOpLambda)  (None, 224, 224, 3)  0           tf.nn.bias_add[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           tf.math.truediv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1024)         4096        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          131200      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,172,929\n",
      "Trainable params: 7,087,233\n",
      "Non-trainable params: 85,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SWONG\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "#specify which pretrained model should be loaded \n",
    "oFlag = \"DenseNet121\"\n",
    "input_tensor = Input(shape=(224, 224, 3),dtype = tf.uint8)\n",
    "\n",
    "if oFlag ==  \"InceptionV3\":    \n",
    "    base_model = InceptionV3(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"ResNet50V2\":\n",
    "    base_model = ResNet50V2(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"MobileNetV2\":\n",
    "    x = tf.cast(input_tensor, tf.float32)\n",
    "    x = tf.keras.applications.mobilenet.preprocess_input(x)\n",
    "    base_model = MobileNetV2(input_tensor=x,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"DenseNet121\":\n",
    "    x = tf.cast(input_tensor, tf.float32)\n",
    "    x = tf.keras.applications.densenet.preprocess_input(x)\n",
    "    base_model = DenseNet121(input_tensor=x,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"EfficientNetB0\":\n",
    "    base_model = EfficientNetB0(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "elif oFlag ==  \"EfficientNetB3\":\n",
    "    base_model = EfficientNetB3(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#add a fully-connected layer and the output layer\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "prediction = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# create the model\n",
    "model = Model(inputs=input_tensor, outputs=prediction)\n",
    "\n",
    "#Add Regularizer to conv and dense layers\n",
    "alpha = 1e-4\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer,Conv2D) or isinstance(layer,Dense):\n",
    "        layer.add_loss(lambda: regularizers.l2(alpha)(layer.kernel))\n",
    "    #if hasattr(layer,'bias_regularizer') and layer.use_bias:\n",
    "    #    layer.add_loss(lambda: regularizers.l2(alpha)(layer.bias))\n",
    "        \n",
    "\n",
    "model.summary()\n",
    "\n",
    "#compile the model\n",
    "oFocalLoss = tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss = \"binary_crossentropy\",metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "checkpoint_path = os.path.join(oModelPath,oFlag + \".hdf5\")\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor ='val_loss',  \n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "#create callbacks for monitoring training\n",
    "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
    "\n",
    "csv_logger      = CSVLogger(os.path.join(oModelPath,oFlag+'.csv'))\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "#create callback for reducing learning rate\n",
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=3, mode = 'min',min_lr=0.000005)\n",
    "\n",
    "callbacks=[cp_callback,tb_callback,csv_logger,early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SWONG\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/100\n",
      "506/506 [==============================] - 251s 467ms/step - loss: 0.9841 - accuracy: 0.6812 - val_loss: 0.4299 - val_accuracy: 0.7734\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42990, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 2/100\n",
      "506/506 [==============================] - 240s 474ms/step - loss: 0.8986 - accuracy: 0.7214 - val_loss: 0.5961 - val_accuracy: 0.6607\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.42990\n",
      "Epoch 3/100\n",
      "506/506 [==============================] - 251s 495ms/step - loss: 0.8787 - accuracy: 0.7305 - val_loss: 0.5569 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.42990\n",
      "Epoch 4/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.8633 - accuracy: 0.7329 - val_loss: 0.5297 - val_accuracy: 0.7087\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42990\n",
      "Epoch 5/100\n",
      "506/506 [==============================] - 247s 487ms/step - loss: 0.8364 - accuracy: 0.7356 - val_loss: 0.4456 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42990\n",
      "Epoch 6/100\n",
      "506/506 [==============================] - 247s 487ms/step - loss: 0.8467 - accuracy: 0.7398 - val_loss: 0.3202 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42990 to 0.32018, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 7/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.8406 - accuracy: 0.7419 - val_loss: 0.3696 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32018\n",
      "Epoch 8/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.8060 - accuracy: 0.7403 - val_loss: 0.4994 - val_accuracy: 0.7377\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32018\n",
      "Epoch 9/100\n",
      "506/506 [==============================] - 247s 487ms/step - loss: 0.8126 - accuracy: 0.7580 - val_loss: 0.5001 - val_accuracy: 0.7545\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32018\n",
      "Epoch 10/100\n",
      "506/506 [==============================] - 249s 491ms/step - loss: 0.8266 - accuracy: 0.7531 - val_loss: 0.4347 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32018\n",
      "Epoch 11/100\n",
      "506/506 [==============================] - 250s 493ms/step - loss: 0.8208 - accuracy: 0.7479 - val_loss: 0.4246 - val_accuracy: 0.7935\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32018\n",
      "Epoch 12/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.8019 - accuracy: 0.7506 - val_loss: 0.3861 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32018\n",
      "Epoch 13/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7961 - accuracy: 0.7498 - val_loss: 0.5542 - val_accuracy: 0.7288\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.32018\n",
      "Epoch 14/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.7842 - accuracy: 0.7565 - val_loss: 0.4646 - val_accuracy: 0.7734\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32018\n",
      "Epoch 15/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.7769 - accuracy: 0.7497 - val_loss: 0.4005 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32018\n",
      "Epoch 16/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.7990 - accuracy: 0.7570 - val_loss: 0.4831 - val_accuracy: 0.7522\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32018\n",
      "Epoch 17/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.7640 - accuracy: 0.7563 - val_loss: 0.5922 - val_accuracy: 0.6362\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32018\n",
      "Epoch 18/100\n",
      "506/506 [==============================] - 247s 489ms/step - loss: 0.8003 - accuracy: 0.7531 - val_loss: 0.4600 - val_accuracy: 0.7924\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32018\n",
      "Epoch 19/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.7913 - accuracy: 0.7705 - val_loss: 0.4053 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.32018\n",
      "Epoch 20/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.7770 - accuracy: 0.7626 - val_loss: 0.3378 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.32018\n",
      "Epoch 21/100\n",
      "506/506 [==============================] - 247s 489ms/step - loss: 0.7796 - accuracy: 0.7626 - val_loss: 0.6220 - val_accuracy: 0.7132\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.32018\n",
      "Epoch 22/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.7744 - accuracy: 0.7596 - val_loss: 0.3579 - val_accuracy: 0.8326\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.32018\n",
      "Epoch 23/100\n",
      "506/506 [==============================] - 247s 489ms/step - loss: 0.7655 - accuracy: 0.7605 - val_loss: 0.4324 - val_accuracy: 0.7913\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.32018\n",
      "Epoch 24/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.7856 - accuracy: 0.7701 - val_loss: 0.3861 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.32018\n",
      "Epoch 25/100\n",
      "506/506 [==============================] - 247s 488ms/step - loss: 0.7712 - accuracy: 0.7553 - val_loss: 0.3648 - val_accuracy: 0.8237\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32018\n",
      "Epoch 26/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.7535 - accuracy: 0.7563 - val_loss: 0.4197 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.32018\n",
      "Epoch 27/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7609 - accuracy: 0.7580 - val_loss: 0.3491 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32018\n",
      "Epoch 28/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.7551 - accuracy: 0.7589 - val_loss: 0.3634 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32018\n",
      "Epoch 29/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7492 - accuracy: 0.7486 - val_loss: 0.3692 - val_accuracy: 0.8337\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32018\n",
      "Epoch 30/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7668 - accuracy: 0.7573 - val_loss: 0.4330 - val_accuracy: 0.7734\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32018\n",
      "Epoch 31/100\n",
      "506/506 [==============================] - 247s 489ms/step - loss: 0.7426 - accuracy: 0.7542 - val_loss: 0.3676 - val_accuracy: 0.8259\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32018\n",
      "Epoch 32/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7407 - accuracy: 0.7633 - val_loss: 0.3370 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32018\n",
      "Epoch 33/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.7572 - accuracy: 0.7653 - val_loss: 0.3132 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.32018 to 0.31323, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 34/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.7623 - accuracy: 0.7648 - val_loss: 0.4031 - val_accuracy: 0.7835\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.31323\n",
      "Epoch 35/100\n",
      "506/506 [==============================] - 250s 493ms/step - loss: 0.7543 - accuracy: 0.7653 - val_loss: 0.4318 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.31323\n",
      "Epoch 36/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.7428 - accuracy: 0.7642 - val_loss: 0.4252 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.31323\n",
      "Epoch 37/100\n",
      "506/506 [==============================] - 249s 491ms/step - loss: 0.7527 - accuracy: 0.7592 - val_loss: 0.3298 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.31323\n",
      "Epoch 38/100\n",
      "506/506 [==============================] - 249s 491ms/step - loss: 0.7484 - accuracy: 0.7647 - val_loss: 0.3364 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.31323\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7398 - accuracy: 0.7633 - val_loss: 0.4692 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.31323\n",
      "Epoch 40/100\n",
      "506/506 [==============================] - 249s 491ms/step - loss: 0.7403 - accuracy: 0.7534 - val_loss: 0.3931 - val_accuracy: 0.8013\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.31323\n",
      "Epoch 41/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7333 - accuracy: 0.7540 - val_loss: 0.3311 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.31323\n",
      "Epoch 42/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7450 - accuracy: 0.7569 - val_loss: 0.3587 - val_accuracy: 0.8382\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.31323\n",
      "Epoch 43/100\n",
      "506/506 [==============================] - 249s 493ms/step - loss: 0.7102 - accuracy: 0.7731 - val_loss: 0.3752 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.31323\n",
      "Epoch 44/100\n",
      "506/506 [==============================] - 248s 490ms/step - loss: 0.7339 - accuracy: 0.7589 - val_loss: 0.3118 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.31323 to 0.31179, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 45/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7410 - accuracy: 0.7752 - val_loss: 0.3820 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.31179\n",
      "Epoch 46/100\n",
      "506/506 [==============================] - 250s 493ms/step - loss: 0.7271 - accuracy: 0.7844 - val_loss: 0.5304 - val_accuracy: 0.7277\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.31179\n",
      "Epoch 47/100\n",
      "506/506 [==============================] - 250s 493ms/step - loss: 0.7107 - accuracy: 0.7752 - val_loss: 0.3610 - val_accuracy: 0.8225\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.31179\n",
      "Epoch 48/100\n",
      "506/506 [==============================] - 250s 494ms/step - loss: 0.7173 - accuracy: 0.7650 - val_loss: 0.4062 - val_accuracy: 0.8225\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.31179\n",
      "Epoch 49/100\n",
      "506/506 [==============================] - 250s 493ms/step - loss: 0.7285 - accuracy: 0.7736 - val_loss: 0.3364 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.31179\n",
      "Epoch 50/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.7287 - accuracy: 0.7685 - val_loss: 0.3344 - val_accuracy: 0.8616\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.31179\n",
      "Epoch 51/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7250 - accuracy: 0.7760 - val_loss: 0.3925 - val_accuracy: 0.8170\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.31179\n",
      "Epoch 52/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7188 - accuracy: 0.7711 - val_loss: 0.3618 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.31179\n",
      "Epoch 53/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7287 - accuracy: 0.7575 - val_loss: 0.3993 - val_accuracy: 0.7935\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.31179\n",
      "Epoch 54/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7280 - accuracy: 0.7633 - val_loss: 0.3494 - val_accuracy: 0.8348\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.31179\n",
      "Epoch 55/100\n",
      "506/506 [==============================] - 248s 491ms/step - loss: 0.7239 - accuracy: 0.7757 - val_loss: 0.3205 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.31179\n",
      "Epoch 56/100\n",
      "506/506 [==============================] - 253s 499ms/step - loss: 0.7042 - accuracy: 0.7789 - val_loss: 0.3886 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.31179\n",
      "Epoch 57/100\n",
      "506/506 [==============================] - 258s 509ms/step - loss: 0.7105 - accuracy: 0.7632 - val_loss: 0.3477 - val_accuracy: 0.8315\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.31179\n",
      "Epoch 58/100\n",
      "506/506 [==============================] - 256s 506ms/step - loss: 0.7139 - accuracy: 0.7717 - val_loss: 0.3141 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.31179\n",
      "Epoch 59/100\n",
      "506/506 [==============================] - 253s 500ms/step - loss: 0.7098 - accuracy: 0.7616 - val_loss: 0.3719 - val_accuracy: 0.8203\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.31179\n",
      "Epoch 60/100\n",
      "506/506 [==============================] - 251s 497ms/step - loss: 0.7136 - accuracy: 0.7666 - val_loss: 0.4180 - val_accuracy: 0.8058\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.31179\n",
      "Epoch 61/100\n",
      "506/506 [==============================] - 249s 492ms/step - loss: 0.7072 - accuracy: 0.7694 - val_loss: 0.3868 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.31179\n",
      "Epoch 62/100\n",
      "506/506 [==============================] - 246s 486ms/step - loss: 0.6917 - accuracy: 0.7791 - val_loss: 0.3837 - val_accuracy: 0.7980\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.31179\n",
      "Epoch 63/100\n",
      "506/506 [==============================] - 245s 484ms/step - loss: 0.7101 - accuracy: 0.7675 - val_loss: 0.3193 - val_accuracy: 0.8549\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.31179\n",
      "Epoch 64/100\n",
      "506/506 [==============================] - 249s 493ms/step - loss: 0.7025 - accuracy: 0.7742 - val_loss: 0.4174 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.31179\n",
      "Epoch 65/100\n",
      "506/506 [==============================] - 253s 500ms/step - loss: 0.7038 - accuracy: 0.7659 - val_loss: 0.4491 - val_accuracy: 0.7846\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.31179\n",
      "Epoch 66/100\n",
      "506/506 [==============================] - 252s 498ms/step - loss: 0.6965 - accuracy: 0.7879 - val_loss: 0.3225 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.31179\n",
      "Epoch 67/100\n",
      "506/506 [==============================] - 255s 504ms/step - loss: 0.6960 - accuracy: 0.7649 - val_loss: 0.3230 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.31179\n",
      "Epoch 68/100\n",
      "506/506 [==============================] - 253s 499ms/step - loss: 0.7079 - accuracy: 0.7665 - val_loss: 0.4175 - val_accuracy: 0.7712\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.31179\n",
      "Epoch 69/100\n",
      "506/506 [==============================] - 251s 495ms/step - loss: 0.7055 - accuracy: 0.7783 - val_loss: 0.3454 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.31179\n",
      "Epoch 70/100\n",
      "506/506 [==============================] - 251s 497ms/step - loss: 0.6956 - accuracy: 0.7834 - val_loss: 0.4438 - val_accuracy: 0.7779\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.31179\n",
      "Epoch 71/100\n",
      "506/506 [==============================] - 254s 501ms/step - loss: 0.7051 - accuracy: 0.7750 - val_loss: 0.3417 - val_accuracy: 0.8538\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.31179\n",
      "Epoch 72/100\n",
      "506/506 [==============================] - 250s 494ms/step - loss: 0.6981 - accuracy: 0.7813 - val_loss: 0.3355 - val_accuracy: 0.8538\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.31179\n",
      "Epoch 73/100\n",
      "506/506 [==============================] - 248s 489ms/step - loss: 0.6941 - accuracy: 0.7831 - val_loss: 0.3362 - val_accuracy: 0.8359\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.31179\n",
      "Epoch 74/100\n",
      "506/506 [==============================] - 246s 486ms/step - loss: 0.6950 - accuracy: 0.7812 - val_loss: 0.3855 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.31179\n",
      "Epoch 75/100\n",
      "506/506 [==============================] - 245s 484ms/step - loss: 0.6985 - accuracy: 0.7809 - val_loss: 0.3055 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.31179 to 0.30548, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 76/100\n",
      "506/506 [==============================] - 243s 479ms/step - loss: 0.6947 - accuracy: 0.7837 - val_loss: 0.3586 - val_accuracy: 0.8404\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.30548\n",
      "Epoch 77/100\n",
      "506/506 [==============================] - 241s 476ms/step - loss: 0.6932 - accuracy: 0.7815 - val_loss: 0.2988 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.30548 to 0.29878, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 78/100\n",
      "506/506 [==============================] - 240s 474ms/step - loss: 0.6944 - accuracy: 0.7695 - val_loss: 0.3863 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.29878\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506/506 [==============================] - 241s 477ms/step - loss: 0.6942 - accuracy: 0.7790 - val_loss: 0.3687 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.29878\n",
      "Epoch 80/100\n",
      "506/506 [==============================] - 243s 481ms/step - loss: 0.6773 - accuracy: 0.7837 - val_loss: 0.4133 - val_accuracy: 0.7868\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.29878\n",
      "Epoch 81/100\n",
      "506/506 [==============================] - 243s 480ms/step - loss: 0.6896 - accuracy: 0.7831 - val_loss: 0.4601 - val_accuracy: 0.7734\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.29878\n",
      "Epoch 82/100\n",
      "506/506 [==============================] - 242s 478ms/step - loss: 0.6898 - accuracy: 0.7743 - val_loss: 0.3392 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.29878\n",
      "Epoch 83/100\n",
      "506/506 [==============================] - 240s 473ms/step - loss: 0.6736 - accuracy: 0.7875 - val_loss: 0.4312 - val_accuracy: 0.7879\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.29878\n",
      "Epoch 84/100\n",
      "506/506 [==============================] - 239s 471ms/step - loss: 0.6792 - accuracy: 0.7783 - val_loss: 0.3388 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.29878\n",
      "Epoch 85/100\n",
      "506/506 [==============================] - 239s 471ms/step - loss: 0.6677 - accuracy: 0.7926 - val_loss: 0.3384 - val_accuracy: 0.8449\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.29878\n",
      "Epoch 86/100\n",
      "506/506 [==============================] - 240s 473ms/step - loss: 0.6949 - accuracy: 0.7769 - val_loss: 0.3690 - val_accuracy: 0.8315\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.29878\n",
      "Epoch 87/100\n",
      "506/506 [==============================] - 242s 477ms/step - loss: 0.6812 - accuracy: 0.7775 - val_loss: 0.3666 - val_accuracy: 0.8270\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.29878\n",
      "Epoch 88/100\n",
      "506/506 [==============================] - 241s 475ms/step - loss: 0.6802 - accuracy: 0.7723 - val_loss: 0.3259 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.29878\n",
      "Epoch 89/100\n",
      "506/506 [==============================] - 243s 479ms/step - loss: 0.6725 - accuracy: 0.7852 - val_loss: 0.3526 - val_accuracy: 0.8237\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.29878\n",
      "Epoch 90/100\n",
      "506/506 [==============================] - 243s 480ms/step - loss: 0.6833 - accuracy: 0.7805 - val_loss: 0.4066 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.29878\n",
      "Epoch 91/100\n",
      "506/506 [==============================] - 243s 480ms/step - loss: 0.6669 - accuracy: 0.7769 - val_loss: 0.3136 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.29878\n",
      "Epoch 92/100\n",
      "506/506 [==============================] - 242s 478ms/step - loss: 0.6749 - accuracy: 0.7788 - val_loss: 0.3846 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.29878\n",
      "Epoch 93/100\n",
      "506/506 [==============================] - 243s 480ms/step - loss: 0.6903 - accuracy: 0.7795 - val_loss: 0.4200 - val_accuracy: 0.7879\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.29878\n",
      "Epoch 94/100\n",
      "506/506 [==============================] - 242s 477ms/step - loss: 0.6703 - accuracy: 0.7802 - val_loss: 0.3029 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.29878\n",
      "Epoch 95/100\n",
      "506/506 [==============================] - 242s 478ms/step - loss: 0.6552 - accuracy: 0.7901 - val_loss: 0.3726 - val_accuracy: 0.8092\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.29878\n",
      "Epoch 96/100\n",
      "506/506 [==============================] - 242s 477ms/step - loss: 0.6783 - accuracy: 0.7838 - val_loss: 0.3624 - val_accuracy: 0.8237\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.29878\n",
      "Epoch 97/100\n",
      "506/506 [==============================] - 242s 478ms/step - loss: 0.6697 - accuracy: 0.7739 - val_loss: 0.2721 - val_accuracy: 0.8795\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.29878 to 0.27205, saving model to C:\\Users\\SWONG\\PRS_project\\Model\\DenseNet121.hdf5\n",
      "Epoch 98/100\n",
      "506/506 [==============================] - 242s 479ms/step - loss: 0.6695 - accuracy: 0.7854 - val_loss: 0.3157 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.27205\n",
      "Epoch 99/100\n",
      "506/506 [==============================] - 242s 478ms/step - loss: 0.6610 - accuracy: 0.7912 - val_loss: 0.3984 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.27205\n",
      "Epoch 100/100\n",
      "506/506 [==============================] - 243s 480ms/step - loss: 0.6595 - accuracy: 0.7789 - val_loss: 0.2926 - val_accuracy: 0.8694\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.27205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12cfc7c8eb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=oTrainingGenerator.n//oTrainingGenerator.batch_size\n",
    "STEP_SIZE_VALID=oValGenerator.n//oValGenerator.batch_size\n",
    "\n",
    "#class weights\n",
    "class_weight = {0:6, 1:1}\n",
    "\n",
    "model.fit(x=oTrainingGenerator, \n",
    "          y=None, \n",
    "          batch_size=16, \n",
    "          epochs=100, \n",
    "          verbose=1, \n",
    "          callbacks=callbacks, \n",
    "          validation_data=oValGenerator,\n",
    "          shuffle=True,\n",
    "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "          class_weight = class_weight,\n",
    "          validation_steps=STEP_SIZE_VALID,\n",
    "          validation_batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot curves on validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= False\n",
    "plt.rcParams['ytick.left']      = True\n",
    "plt.rcParams['ytick.labelleft'] = True\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "records     = pd.read_csv(os.path.join(oModelPath,oFlag+'.csv'))\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.1,0.2,0.3,0.4,0.50])\n",
    "plt.title('Loss curve',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_accuracy'],label=\"validation\")\n",
    "plt.plot(records['accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9])\n",
    "plt.title('Accuracy curve',fontsize=12)\n",
    "ax.legend()\n",
    "#save the plot\n",
    "plotpath  = os.path.join(oModelPath,oFlag + '_plot.png')\n",
    "plt.savefig(plotpath)\n",
    "#Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Save the model plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Path to plot: D:\\PRS_project\\Model\\MobileNetV2_plot.png\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\rggop\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\rggop\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
